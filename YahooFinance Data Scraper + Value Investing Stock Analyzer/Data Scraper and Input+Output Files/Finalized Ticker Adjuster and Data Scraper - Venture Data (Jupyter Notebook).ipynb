{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting them both together.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, the ticker file reader + text adjuster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Mac/Desktop/Investing/Financial Data/Ticker Lists/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading file for list of tickers\n",
    "ticker_list_tsxv = []\n",
    "\n",
    "with open('TSXV Tickers.csv', 'r') as file:\n",
    "    csv_file = csv.reader(file)\n",
    "    for row in csv_file:\n",
    "        ticker_list_tsxv.append(row)    \n",
    "\n",
    "#Check a sample of the csv data\n",
    "print(ticker_list_tsxv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating relevant data\n",
    "ticker_list_test = []\n",
    "\n",
    "for x in range(len(ticker_list_tsxv)):\n",
    "    ticker_list_test.append(ticker_list_tsxv[x][0])\n",
    "\n",
    "ticker_list_test = ticker_list_test[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the \".V\" for Venture tickers and adjusting other tickers to proper form\n",
    "tsx_list = []\n",
    "\n",
    "for x in ticker_list_test:\n",
    "    if \".\" in x:\n",
    "        tsx_list.append(x.replace(\".\",\"-\") + \".TO\")\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        tsx_list.append(x + \".TO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, the actual data scraper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining formatting tools\n",
    "\n",
    "class FormattingTool:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def value_to_float(self, x):\n",
    "        if type(x) == float or type(x) == int:\n",
    "            return x\n",
    "        if 'K' in x:\n",
    "            if len(x) > 1:\n",
    "                return float(x.replace('K', '')) * 1000\n",
    "            return 1000.0\n",
    "        if 'M' in x:\n",
    "            if len(x) > 1:\n",
    "                return float(x.replace('M', '')) * 1000000\n",
    "            return 1000000.0\n",
    "        if 'B' in x:\n",
    "            if len(x) > 1:\n",
    "                return float(x.replace('B', '')) * 1000000000\n",
    "        if 'T' in x:\n",
    "            return float(x.replace('T', '')) * 1000000000000\n",
    "        return 0.0\n",
    "    \n",
    "    def create_pd_dataframe(self):\n",
    "        pd.options.display.float_format = '{:,}'.format\n",
    "        df_columns = [\"Ticker\",\"Date\",\"Price\",\"Shares Outstanding\",\"Market Cap\",\"EV\",\"EBITDA\",\"EV/EBITDA\",\"D/E\",\"BV/Share\",\"Total Cash\",\"Total Liabilities\",\"Total Revenue\",\"Operating Cash Flow\", \"BS Recent Date\", \"CF Recent Date\", \"IS Recent Date\"]\n",
    "        stock_info_df = pd.DataFrame(data = None, columns = df_columns, index = [0])    \n",
    "        return stock_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining data scraping functions\n",
    "#note: cash flows have been pulled for TTM, rather than simply most recent year-end\n",
    "\n",
    "\n",
    "class FinancialDataScraper:\n",
    "    def __init__(self, ticker, stock_data):\n",
    "        self.ticker = ticker\n",
    "\n",
    "        \n",
    "    #define function to pull most recent dates for all financial statements of ticker company\n",
    "    def financials_date_scrape(self):\n",
    "        \n",
    "        recent_dates_temp = []\n",
    "        #balance sheet date\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}/balance-sheet?p={}'.format(self.ticker,self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        bs_date_containers = html_soup.find('div', class_ = \"D(tbr) C($primaryColor)\")\n",
    "        bs_dates = []\n",
    "        \n",
    "        try:\n",
    "            bs_dates = bs_date_containers.find_all('span')\n",
    "            \n",
    "            bs_dates[0]\n",
    "\n",
    "            x = 0\n",
    "            for x in range(len(bs_dates)):\n",
    "                bs_dates[x] = bs_dates[x].text\n",
    "                x+=1\n",
    "\n",
    "            try:\n",
    "                recent_dates_temp.append(bs_dates[1])\n",
    "\n",
    "            except IndexError:\n",
    "                recent_dates_temp.append(\"Null\")\n",
    "                \n",
    "        except AttributeError:\n",
    "                recent_dates_temp.append(\"Null\")            \n",
    "\n",
    "            \n",
    "            \n",
    "        #CF stmt date\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}/cash-flow?p={}'.format(self.ticker,self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        cf_date_containers = html_soup.find('div', class_ = \"D(tbr) C($primaryColor)\")\n",
    "        cf_dates = []\n",
    "        \n",
    "        try:\n",
    "            cf_dates = cf_date_containers.find_all('span')\n",
    "            cf_dates[0]\n",
    "\n",
    "            x = 0\n",
    "            for x in range(len(cf_dates)):\n",
    "                cf_dates[x] = cf_dates[x].text\n",
    "                x+=1\n",
    "\n",
    "            try:\n",
    "                recent_dates_temp.append(cf_dates[2])\n",
    "            except IndexError:\n",
    "                try: \n",
    "                    recent_dates_temp.append(cf_dates[1])\n",
    "                except IndexError:\n",
    "                    recent_dates_temp.append(\"Null\")\n",
    "        except AttributeError:\n",
    "                    recent_dates_temp.append(\"Null\")            \n",
    "                \n",
    "        \n",
    "        \n",
    "        #IS stmt date\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}/financials?p={}'.format(self.ticker, self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        is_date_containers = html_soup.find('div', class_ = \"D(tbr) C($primaryColor)\")\n",
    "        is_dates = []\n",
    "        try:\n",
    "            is_dates = is_date_containers.find_all('span')\n",
    "            is_dates[0]\n",
    "\n",
    "            x = 0\n",
    "            for x in range(len(is_dates)):\n",
    "                is_dates[x] = is_dates[x].text\n",
    "                x+=1\n",
    "\n",
    "            try:\n",
    "                recent_dates_temp.append(is_dates[2])\n",
    "            except IndexError:\n",
    "                try: \n",
    "                    recent_dates_temp.append(is_dates[1])\n",
    "                except IndexError:\n",
    "                    recent_dates_temp.append(\"Null\")\n",
    "        except AttributeError:\n",
    "                    recent_dates_temp.append(\"Null\")\n",
    "        \n",
    "        return(recent_dates_temp)\n",
    "    \n",
    "    \n",
    "    #define function to scrape selected balance sheet data\n",
    "    #returns cash and total liabilities to a temporary variable to be extracted and later pulled into a df\n",
    "    def balance_sheet_data_scrape(self):\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}/balance-sheet?p={}'.format(self.ticker,self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    " \n",
    "        #find the ca$h_money\n",
    "        q_totalcash_div = html_soup.find('div', text = \"Total Cash\")\n",
    "\n",
    "        try:\n",
    "            q_totalcash_container = q_totalcash_div.parent\n",
    "\n",
    "            q_totalcash_values = []\n",
    "            q_totalcash_values.append(q_totalcash_container.text)\n",
    "\n",
    "            for x in q_totalcash_container.next_siblings:\n",
    "                q_totalcash_values.append(x.text)\n",
    "\n",
    "            q_totalcash_values = q_totalcash_values[1:]\n",
    "\n",
    "            y = 0\n",
    "            for x in (q_totalcash_values):\n",
    "                if x == '-':\n",
    "                    q_totalcash_values[y] = x.replace('-',\"0\")\n",
    "                    q_totalcash_values[y] = int(float(q_totalcash_values[y]))\n",
    "\n",
    "                else:\n",
    "                    q_totalcash_values[y] = int(float(x.replace(',',\"\")))\n",
    "                y+=1\n",
    "\n",
    "        except AttributeError:\n",
    "                q_totalcash_values = [0, 0, 0, 0]\n",
    "\n",
    "        stock_data_temp.append(q_totalcash_values[0])\n",
    "        \n",
    "        \n",
    "        #find the total liabilities\n",
    "        q_totallibs_div = html_soup.find('div', text = \"Total Liabilities\")\n",
    "    \n",
    "        try: \n",
    "            q_totallibs_container = q_totallibs_div.parent\n",
    "\n",
    "            q_totallibs_values = []\n",
    "            q_totallibs_values.append(q_totallibs_container.text)\n",
    "\n",
    "            for x in q_totallibs_container.next_siblings:\n",
    "                q_totallibs_values.append(x.text)\n",
    "\n",
    "            q_totallibs_values = q_totallibs_values[1:]\n",
    "\n",
    "            y = 0\n",
    "            for x in (q_totallibs_values):\n",
    "                if x == '-':\n",
    "                    q_totallibs_values[y] = x.replace('-',\"0\")\n",
    "                    q_totallibs_values[y] = int(float(q_totallibs_values[y]))\n",
    "\n",
    "                else:\n",
    "                    q_totallibs_values[y] = int(float(x.replace(',',\"\")))\n",
    "                y+=1\n",
    "\n",
    "        except AttributeError:\n",
    "            q_totallibs_values = [0, 0, 0, 0]\n",
    "            \n",
    "        stock_data_temp.append(q_totallibs_values[0])\n",
    "        \n",
    "        #time.sleep(30)\n",
    "        return stock_data_temp\n",
    "    \n",
    "    \n",
    "    \n",
    "    #define function to pull operating cash flow\n",
    "    def cashflow_data_scrape(self):\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}/cash-flow?p={}'.format(self.ticker, self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        #op cash flow\n",
    "        q_opcashflow_div = html_soup.find('div', text = \"Net cash provided by operating activites\")\n",
    "\n",
    "        try:\n",
    "            q_opcashflow_container = q_opcashflow_div.parent\n",
    "\n",
    "            q_opcashflow_values = []\n",
    "            q_opcashflow_values.append(q_opcashflow_container.text)\n",
    "\n",
    "            for x in q_opcashflow_container.next_siblings:\n",
    "                q_opcashflow_values.append(x.text)\n",
    "\n",
    "            q_opcashflow_values = q_opcashflow_values[1:]\n",
    "\n",
    "            y = 0\n",
    "            for x in (q_opcashflow_values):\n",
    "                if x == '-':\n",
    "                    q_opcashflow_values[y] = x.replace('-',\"0\")\n",
    "                    q_opcashflow_values[y] = int(float(q_opcashflow_values[y]))\n",
    "\n",
    "                else:\n",
    "                    q_opcashflow_values[y] = int(float(x.replace(',',\"\")))\n",
    "                y+=1\n",
    "\n",
    "        except AttributeError:\n",
    "            q_opcashflow_values = [0, 0, 0, 0, 0]\n",
    "        \n",
    "        try:\n",
    "            stock_data_temp.append(q_opcashflow_values[1])\n",
    "        except IndexError:\n",
    "            stock_data_temp.append(q_opcashflow_values[0])            \n",
    "        \n",
    "        #time.sleep(10)\n",
    "        return stock_data_temp\n",
    "    \n",
    "    \n",
    "    def incomestmt_data_scrape(self):\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}/financials?p={}'.format(self.ticker, self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        #revenue\n",
    "        q_rev_div = html_soup.find('div', text = \"Total Revenue\")\n",
    "\n",
    "        try:\n",
    "            q_rev_container = q_rev_div.parent\n",
    "\n",
    "            q_rev_values = []\n",
    "            q_rev_values.append(q_rev_container.text)\n",
    "\n",
    "            for x in q_rev_container.next_siblings:\n",
    "                q_rev_values.append(x.text)\n",
    "\n",
    "            q_rev_values = q_rev_values[1:]\n",
    "\n",
    "            y = 0\n",
    "            for x in (q_rev_values):\n",
    "                if x == '-':\n",
    "                    q_rev_values[y] = x.replace('-',\"0\")\n",
    "                    q_rev_values[y] = int(float(q_rev_values[y]))\n",
    "\n",
    "                else:\n",
    "                    q_rev_values[y] = int(float(x.replace(',',\"\")))\n",
    "                y+=1\n",
    "                \n",
    "        except AttributeError:\n",
    "            q_rev_values = [0, 0, 0, 0, 0]\n",
    "         \n",
    "        try:\n",
    "            stock_data_temp.append(q_rev_values[1])\n",
    "        except IndexError:\n",
    "            stock_data_temp.append(q_rev_values[0])        \n",
    "        \n",
    "        #time.sleep(10)\n",
    "        return stock_data_temp\n",
    "\n",
    "    \n",
    "    \n",
    "    #define function to pull various relevant data points;\n",
    "    #including Market Cap, Enterprise Value,EBITDA, D/E, BV/Share, and shares outstanding\n",
    "    def otherfinancials_data_scrape(self):\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}/key-statistics?p={}'.format(self.ticker, self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        #market cap\n",
    "        market_cap_div = html_soup.find(text = \"Market Cap (intraday)\")\n",
    "\n",
    "        try:\n",
    "            market_cap_container = market_cap_div.parent.parent\n",
    "\n",
    "            market_cap = []\n",
    "            market_cap.append(market_cap_div)\n",
    "\n",
    "            market_cap.append(market_cap_div.parent.parent.next_sibling.text)\n",
    "\n",
    "            formatting_tool = FormattingTool()\n",
    "\n",
    "            if market_cap[1] == 'N/A':\n",
    "                stock_data_temp.append(0)\n",
    "            else:\n",
    "                stock_data_temp.append(formatting_tool.value_to_float(market_cap[1]))\n",
    "        except AttributeError:\n",
    "            stock_data_temp.append(0)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        #enterprise value\n",
    "        EV_div = html_soup.find(text = \"Enterprise Value\")\n",
    "\n",
    "        try:\n",
    "            EV_container = EV_div.parent.parent\n",
    "\n",
    "            EV = []\n",
    "            EV.append(EV_div)\n",
    "\n",
    "            EV.append(EV_div.parent.parent.next_sibling.text)\n",
    "\n",
    "            stock_data_temp.append(formatting_tool.value_to_float(EV[1]))\n",
    "        except AttributeError:\n",
    "            stock_data_temp.append(0)\n",
    "\n",
    "        \n",
    "        #EBITDA\n",
    "        EBITDA_div = html_soup.find(text = \"EBITDA\")\n",
    "\n",
    "        try:\n",
    "            EBITDA_container = EBITDA_div.parent.parent\n",
    "\n",
    "            EBITDA = []\n",
    "            EBITDA.append(EBITDA_div)\n",
    "\n",
    "            EBITDA.append(EBITDA_div.parent.parent.next_sibling.text)\n",
    "\n",
    "            if EBITDA[1] == 'N/A':\n",
    "                stock_data_temp.append(0)\n",
    "            else:\n",
    "                stock_data_temp.append(formatting_tool.value_to_float(EBITDA[1]))        \n",
    "        except AttributeError:\n",
    "            stock_data_temp.append(0)            \n",
    "        \n",
    "        \n",
    "        #enterprise value/EBITDA\n",
    "        EV_to_EBITDA_div = html_soup.find(text = \"Enterprise Value/EBITDA\")\n",
    "\n",
    "        try:\n",
    "            EV_to_EBITDA_container = EV_to_EBITDA_div.parent.parent\n",
    "\n",
    "            EV_to_EBITDA = []\n",
    "            EV_to_EBITDA.append(EV_to_EBITDA_div)\n",
    "\n",
    "            EV_to_EBITDA.append(EV_to_EBITDA_div.parent.parent.next_sibling.text)\n",
    "\n",
    "\n",
    "            if EV_to_EBITDA[1] == 'N/A':\n",
    "                stock_data_temp.append(0)\n",
    "            else:\n",
    "                stock_data_temp.append(formatting_tool.value_to_float(EV_to_EBITDA[1]))\n",
    "        \n",
    "        except AttributeError:\n",
    "            stock_data_temp.append(0)\n",
    "        \n",
    "        \n",
    "        #debt to equity\n",
    "        debt_to_equity_div = html_soup.find(text = \"Total Debt/Equity\")\n",
    "        \n",
    "        try:\n",
    "            debt_to_equity_container = debt_to_equity_div.parent.parent\n",
    "\n",
    "            debt_to_equity = []\n",
    "            debt_to_equity.append(debt_to_equity_div)\n",
    "\n",
    "            debt_to_equity.append(debt_to_equity_div.parent.parent.next_sibling.text)\n",
    "\n",
    "            if debt_to_equity[1] == 'N/A':\n",
    "                stock_data_temp.append(0)\n",
    "            else:\n",
    "                stock_data_temp.append(formatting_tool.value_to_float(debt_to_equity[1]))\n",
    "        except AttributeError:\n",
    "            stock_data_temp.append(0)\n",
    "        \n",
    "\n",
    "        #BV per share\n",
    "        book_value_ps_div = html_soup.find(text = \"Book Value Per Share\")\n",
    "\n",
    "        try:\n",
    "            book_value_ps_container = book_value_ps_div.parent.parent\n",
    "\n",
    "            book_value_ps = []\n",
    "            book_value_ps.append(book_value_ps_div)\n",
    "\n",
    "            book_value_ps.append(book_value_ps_div.parent.parent.next_sibling.text)\n",
    "\n",
    "            if book_value_ps[1] == 'N/A':\n",
    "                stock_data_temp.append(0)\n",
    "            else:\n",
    "                stock_data_temp.append(formatting_tool.value_to_float(book_value_ps[1]))\n",
    "        except AttributeError:\n",
    "            stock_data_temp.append(0)           \n",
    "        \n",
    "        \n",
    "        #shares outstanding\n",
    "        shares_outstanding_div = html_soup.find(text = \"Shares Outstanding\")\n",
    "\n",
    "        try:\n",
    "            shares_outstanding_container = shares_outstanding_div.parent.parent\n",
    "\n",
    "            shares_outstanding = []\n",
    "            shares_outstanding.append(shares_outstanding_div)\n",
    "\n",
    "            shares_outstanding.append(shares_outstanding_div.parent.parent.next_sibling.text)\n",
    "\n",
    "            if shares_outstanding[1] == 'N/A':\n",
    "                stock_data_temp.append(0)\n",
    "            else:\n",
    "                stock_data_temp.append(formatting_tool.value_to_float(shares_outstanding[1])) \n",
    "        except:\n",
    "            stock_data_temp.append(0)            \n",
    "        \n",
    "        \n",
    "        #time.sleep(15)\n",
    "        return stock_data_temp\n",
    "\n",
    "        \n",
    "        \n",
    "    #finally, define function to pull price at that point in time\n",
    "    def price_data_scrape(self):\n",
    "        URL = 'https://ca.finance.yahoo.com/quote/{}?p={}'.format(self.ticker, self.ticker)\n",
    "        page = requests.get(URL)\n",
    "        html_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        formatting_tool = FormattingTool()\n",
    "        \n",
    "        try:\n",
    "            stock_price_container = html_soup.find('div', class_=\"My(6px) Pos(r) smartphone_Mt(6px)\")\n",
    "\n",
    "            stock_price = []\n",
    "            stock_price.append(dt.now())\n",
    "\n",
    "            stock_price.append(stock_price_container.div.span.text)\n",
    "\n",
    "\n",
    "            if stock_price[1] == 'N/A':\n",
    "                stock_data_temp.append(0)\n",
    "            else:\n",
    "                stock_data_temp.append(float(stock_price[1].replace(\",\",\"\")))\n",
    "\n",
    "        except AttributeError:\n",
    "            stock_data_temp.append(0)\n",
    "\n",
    "        now = dt.now()\n",
    "        date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "        stock_data_temp.append(date_time)\n",
    "        \n",
    "        #time.sleep(15)\n",
    "        return stock_data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing ground\n",
    "\n",
    "\n",
    "stock_data = []\n",
    "\n",
    "tsx_list_test = ['CSU.TO']\n",
    "\n",
    "print(tsx_list_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing ground\n",
    "\n",
    "\n",
    "stock_data_df = FormattingTool()\n",
    "stock_data_df = stock_data_df.create_pd_dataframe()\n",
    "\n",
    "y = 0\n",
    "for x in tsx_list:\n",
    "    \n",
    "    print(x)\n",
    "    #call financialdatascraper class\n",
    "    analysis = FinancialDataScraper(x, stock_data)\n",
    "\n",
    "    #initiailze df with ticker 'x'\n",
    "    stock_data_df.at[y,'Ticker'] = x\n",
    "    \n",
    "    #scrape dates first\n",
    "    stock_data_temp = analysis.financials_date_scrape()\n",
    "    stock_data_df.at[y, 'BS Recent Date'] = (stock_data_temp[0])\n",
    "    stock_data_df.at[y, 'CF Recent Date'] = (stock_data_temp[1])\n",
    "    stock_data_df.at[y, 'IS Recent Date'] = (stock_data_temp[2])\n",
    "    \n",
    "    stock_data_temp = []\n",
    "\n",
    "    \n",
    "    #scrape balance sheet data    \n",
    "    stock_data_temp = analysis.balance_sheet_data_scrape()\n",
    "    stock_data_df.at[y,'Total Cash'] = float(stock_data_temp[0])\n",
    "    stock_data_df.at[y,'Total Liabilities'] = float(stock_data_temp[1])\n",
    "    \n",
    "    stock_data_temp = []\n",
    "\n",
    "   \n",
    "    #scrape op cash flow data\n",
    "    stock_data_temp = analysis.cashflow_data_scrape()\n",
    "    stock_data_df.at[y,'Operating Cash Flow'] = float(stock_data_temp[0])\n",
    "    \n",
    "    stock_data_temp = []\n",
    "\n",
    "    \n",
    "    #scrape income statement data\n",
    "    stock_data_temp = analysis.incomestmt_data_scrape()\n",
    "    stock_data_df.at[y,'Total Revenue'] = float(stock_data_temp[0])\n",
    "    \n",
    "    stock_data_temp = []\n",
    "    \n",
    "    \n",
    "    #scrape other financial data\n",
    "    stock_data_temp = analysis.otherfinancials_data_scrape()\n",
    "    stock_data_df.at[y,'Market Cap'] = (stock_data_temp[0])\n",
    "    stock_data_df.at[y,'EV'] = stock_data_temp[1]\n",
    "    stock_data_df.at[y,'EBITDA'] = stock_data_temp[2]\n",
    "    stock_data_df.at[y,'EV/EBITDA'] = stock_data_temp[3]\n",
    "    stock_data_df.at[y,'D/E'] = stock_data_temp[4]\n",
    "    stock_data_df.at[y,'BV/Share'] = stock_data_temp[5]\n",
    "    stock_data_df.at[y,'Shares Outstanding'] = stock_data_temp[6]\n",
    "\n",
    "    stock_data_temp = []\n",
    "\n",
    "    \n",
    "    #pull price, current date/time\n",
    "    stock_data_temp = analysis.price_data_scrape()\n",
    "    stock_data_df.at[y,'Price'] = stock_data_temp[0]\n",
    "    stock_data_df.at[y,'Date'] = stock_data_temp[1]\n",
    "  \n",
    "    stock_data_temp = []\n",
    "\n",
    "    time.sleep(10)\n",
    "    #loop counter\n",
    "    y+=1\n",
    "    \n",
    "\n",
    "stock_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_df.to_csv(r'C:\\Users\\Mac\\Desktop\\Investing\\Financial Data\\TSX_Data_Final.csv',index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
